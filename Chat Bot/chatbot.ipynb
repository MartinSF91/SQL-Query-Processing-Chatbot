{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import chromadb\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sqlparse\n",
    "import re\n",
    "import json\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m collection \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcreate_collection(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDSPD\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# ADM Check [Handling and Storage.Op.8177]\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmain\u001b[49m(columns)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "client.delete_collection(name=\"docs\")\n",
    "collection = client.create_collection(name=\"docs\")\n",
    "\n",
    "columns = \"DSPD\" # ADM Check [Handling and Storage.Op.8177]\n",
    "\n",
    "main(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(columns):\n",
    "\n",
    "    EMBEDDING_MODEL = \"mxbai-embed-large:latest\"\n",
    "    LLM_MODEL = \"gemma2:2b\"\n",
    "\n",
    "    documents = read_in_excel_files()\n",
    "\n",
    "    processed_documents = preprocess_queries(documents)\n",
    "\n",
    "    PROMPT = f\"Is there a Report containing Columns '{', '.join(columns.split())}'? If so, provide Report Name\"\n",
    "\n",
    "    document_embeddings = document_embedding(processed_documents, EMBEDDING_MODEL)\n",
    "\n",
    "    prompt_embeddings = ollama.embeddings(model=EMBEDDING_MODEL, prompt=columns)\n",
    "\n",
    "    retrieval_results = retrieve(prompt_embeddings)\n",
    "\n",
    "    similarity = calculate_similarity(document_embeddings, prompt_embeddings, retrieval_results)\n",
    "\n",
    "    generate_answer(LLM_MODEL, retrieval_results, PROMPT, similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `read_in_excel_files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_excel_files():\n",
    "\n",
    "    PATH = \"../Query Processing/1_migrated_excel_queries/Queries_3.xlsx\"\n",
    "\n",
    "    excel_data = glob.glob(PATH)\n",
    "\n",
    "    dataframes = [pd.read_excel(data, engine=\"openpyxl\") for data in excel_data]\n",
    "    query_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `preprocess_queries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_queries(query_df):\n",
    "\n",
    "    query_df = query_df.dropna(subset=[\"SQL\"]).fillna(\"\")\n",
    "\n",
    "    SQL_EXPRESSIONS = [\n",
    "        \"SELECT\",\n",
    "        \"DISTINCT\",\n",
    "        \"FROM\",\n",
    "        \"TRIM\",\n",
    "        \"BOTH\",\n",
    "        \"SUBSTR\",\n",
    "        \"COUNT\",\n",
    "        \"IN\",\n",
    "        \"AS\",\n",
    "        \"ORDER BY\",\n",
    "        \"GROUP BY\",\n",
    "        \"AND\",\n",
    "        \"WHERE\",\n",
    "        \"CONCAT\",\n",
    "        \"CASE\",\n",
    "        \"SUM\",\n",
    "        \"WHEN\",\n",
    "        \"TO_DATE\",\n",
    "        \"TO_CHAR\",\n",
    "        \"CAST\",\n",
    "        \"BETWEEN\",\n",
    "        \"TRUNC\",\n",
    "        \"OVER\",\n",
    "        \"PARTITION BY\",\n",
    "        \"TIMESTAMP\",\n",
    "        \"THEN\",\n",
    "        \"ELSE\",\n",
    "        \"NULL\",\n",
    "        \"END\",\n",
    "        \"INNER JOIN\",\n",
    "        \"OUTER JOIN\",\n",
    "        \"SQL\",\n",
    "        \"CURRENT_DATE\",\n",
    "        \"YYYY\",\n",
    "        \"MMMM\",\n",
    "        \"SSSS\",\n",
    "        \"DAYS\",\n",
    "        \"CURRENT_YEAR\",\n",
    "        \"FIRST_VALUE\",\n",
    "        \"AT\",\n",
    "    ]\n",
    "\n",
    "    query_df[\"SQL\"] = (query_df[\"SQL\"]\n",
    "                       .str.replace('ê', 'e').str.replace('é', 'e').str.replace('è', 'e').str.replace('à', 'a').str.replace('ç', 'c')\n",
    "                       .str.replace('ô', 'o').str.replace('û', 'u').str.replace('ù', 'u').str.replace('î', 'i').str.replace('ï', 'i')\n",
    "                       .str.replace('â', 'a').str.replace('ä', 'a').str.replace('ö', 'o').str.replace('ü', 'u').str.replace('ÿ', 'y')\n",
    "                       .str.replace('ñ', 'n').str.replace('É', 'E').str.replace('È', 'E').str.replace('À', 'A').str.replace('Ç', 'C')\n",
    "                       .str.replace('Ô', 'O').str.replace('Û', 'U').str.replace('Ù', 'U').str.replace('Î', 'I').str.replace('Ï', 'I')\n",
    "                       .str.replace('Â', 'A').str.replace('Ä', 'A').str.replace('Ö', 'O').str.replace('Ü', 'U').str.replace('Ÿ', 'Y')\n",
    "                       .str.replace('Ñ', 'N')\n",
    "    )\n",
    "\n",
    "    with_pattern = r'WITH\\s+\"\\w+\"\\s+AS\\s*\\(.*?\\)\\s*SELECT'\n",
    "    pattern_2 = r'\"[^\"]*\"\\.'\n",
    "    pattern_3 = r'\\w+\\.'\n",
    "\n",
    "    for index, query in enumerate(query_df[\"SQL\"]):\n",
    "        formatted_query = query.upper()\n",
    "        formatted_query = sqlparse.format(formatted_query, reindent=True, keyword_case='upper', strip_comments=True).strip()\n",
    "        formatted_query = formatted_query.replace(\"'\", '\"').replace(\"\\n\", \" \")\n",
    "        formatted_query = re.sub(with_pattern, 'SELECT', formatted_query, flags=re.DOTALL)\n",
    "        formatted_query = re.sub(pattern_2, '', formatted_query)\n",
    "        formatted_query = re.sub(pattern_3, '', formatted_query)\n",
    "        formatted_query = \" \".join(formatted_query.split())\n",
    "        formatted_query = re.sub(r'\"(\\w+)\" AS \"\\1\"', r'\"\\1\"', formatted_query)\n",
    "        formatted_query = re.sub(r'(\"\\w+\")\\s+\"\\w+\"', r'\\1', formatted_query)\n",
    "        formatted_query = re.sub(r'[\",\\'\\-\"\\)\\(=<>\\:/\\*\\d]', \" \", formatted_query)\n",
    "        formatted_query = re.sub(r'\\b[a-zA-Z]\\b', \" \", formatted_query)\n",
    "\n",
    "        for expr in SQL_EXPRESSIONS:\n",
    "            formatted_query = formatted_query.replace(expr, \" \")\n",
    "\n",
    "\n",
    "        query_df.at[index, 'SQL'] = formatted_query\n",
    "\n",
    "    query_df[\"SQL\"] = query_df['SQL'].apply(lambda x: f\"Columns: {x}\")\n",
    "    query_df[\"Report Name\"] = query_df['Report Name'].apply(lambda x: f\"Report Name: {x}\")\n",
    "    query_df = query_df[[\"Report Name\", \"SQL\"]]\n",
    "\n",
    "    documents = []\n",
    "    for index, row in query_df.iterrows():\n",
    "        documents.append(f\"{' '.join(row['Report Name'].split())}, {' '.join(row['SQL'].split())}\")\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `document_embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_embedding(documents, EMBEDDING_MODEL):\n",
    "    document_embeddings = []\n",
    "\n",
    "    for i, d in enumerate(documents):\n",
    "        response = ollama.embed(model=EMBEDDING_MODEL, input=d)\n",
    "        embeddings = response[\"embeddings\"]\n",
    "        document_embeddings.append(embeddings)\n",
    "        collection.add(ids=[str(i)], embeddings=embeddings, documents=[d])\n",
    "\n",
    "    return document_embeddings,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `retrieve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(embedded_prompt):\n",
    "    retrieval_results = collection.query(query_embeddings=embedded_prompt[\"embedding\"], n_results=1)\n",
    "    return retrieval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `calculate_similarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(document_embeddings, embedded_prompt, retrieval_results):\n",
    "    document_vector = np.array(document_embeddings[0][int(retrieval_results[\"ids\"][0][0])]).reshape(1, -1)\n",
    "    prompt_vector = np.array(embedded_prompt[\"embedding\"]).reshape(1, -1)\n",
    "    similarity = cosine_similarity(document_vector, prompt_vector).flatten()[0]\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `generate_answer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(LLM_MODEL, retrieval_results, PROMPT, similarity):\n",
    "    output = ollama.generate(\n",
    "        model=LLM_MODEL,\n",
    "        prompt=f\"Using this data: {retrieval_results[\"documents\"][0][0]}. Respond to this prompt: {PROMPT}\",\n",
    "    )\n",
    "\n",
    "    print(output[\"response\"])\n",
    "    print(f\"Similarity: {round(similarity * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
