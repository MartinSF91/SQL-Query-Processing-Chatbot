{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Imports`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import chromadb\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `MAIN Embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Time: 8.19s\n"
     ]
    }
   ],
   "source": [
    "client.delete_collection(name=\"docs\")\n",
    "collection = client.create_collection(name=\"docs\")\n",
    "\n",
    "PATH = \"../Query Processing/4_json_results/migrated_query_data.json\"\n",
    "documents = load_json(PATH)\n",
    "document_embeddings = document_embedding(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `MAIN get_output_main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided data, there is a report named **'YVES INBOUND NOT COMPLETED'** that contains the columns  'ACT_END_DATE' and 'BUA_NO_START'. \n",
      "\n",
      "\n",
      "Let me know if you have any other data requests! \n",
      "\n",
      "Reports with highest Similarity:\n",
      "Similarity for Report Name 'YVES INBOUND NOT COMPLETED': 63.53%\n",
      "Similarity for Report Name 'ADM CHECK': 60.53%\n",
      "Similarity for Report Name 'ACTIVITY FOLLOW UP': 58.68%\n",
      "Runtime: 59.72s.\n"
     ]
    }
   ],
   "source": [
    "desired_columns = [\"ACT_END_DATE, BUA_NO_START\"] # YVES INBOUND NOT COMPLETED\n",
    "# desired_columns = [\"ONHANDQTY, PARTNO\"] # CWIS ASTRO CDC CMR\n",
    "# desired_columns = [\"ECARRNO\"] # MIP 490 INBOUND PALLETS AND TOTAL OH\n",
    "# desired_columns = [\"ASTRO_TRIP_ID\", \"ITEM_ID\"] # YVES STORE ORDERS VOLUME BY DAY\n",
    "# desired_columns = [ # AAYE STOCKAGE\n",
    "#     \"AMOONCR\",\n",
    "#     \"CARRSTAT\",\n",
    "#     \"CARRTYPE\",\n",
    "#     \"DIVCODE\",\n",
    "#     \"ECARRNO\",\n",
    "#     \"FLEXDAYS\",\n",
    "#     \"G08PDATE\",\n",
    "#     \"LDCT\",\n",
    "#     \"LOCKCODE\",\n",
    "#     \"LOTID\",\n",
    "# ]\n",
    "\n",
    "get_output_main(desired_columns, document_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Query Embedding Methods`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `load_json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(PATH):\n",
    "\n",
    "    try:\n",
    "        with open(PATH, 'r') as json_file:\n",
    "            query_data = json.load(json_file)\n",
    "\n",
    "        report_names = []\n",
    "        report_columns = []\n",
    "\n",
    "        for key, value in query_data.items():\n",
    "            report_names.append(key.strip())\n",
    "            report_columns.append(value[\"columns_cleansed\"])\n",
    "\n",
    "        df = pd.DataFrame({\"report_name\": report_names, \"report_columns\": report_columns})\n",
    "        df['report_columns'] = df[\"report_columns\"].apply(liste_zu_string)\n",
    "\n",
    "        df[\"documents\"] = \"Report Name \" + \"'\" + df[\"report_name\"]+ \"'\" + \" contains columns: \" + df[\"report_columns\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\")\n",
    "\n",
    "    return df[[\"documents\"]].apply(zeile_zu_string, axis=1).tolist()\n",
    "\n",
    "\n",
    "def liste_zu_string(liste):\n",
    "    return ', '.join(map(str, liste))\n",
    "\n",
    "def zeile_zu_string(row):\n",
    "    return ', '.join(map(str, row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `document_embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_embedding(documents):\n",
    "    start = time.time()\n",
    "    document_embeddings = []\n",
    "\n",
    "    for i, doc in enumerate(documents):\n",
    "        response = ollama.embed(model=\"mxbai-embed-large:latest\", input=doc)\n",
    "        embeddings = response[\"embeddings\"]\n",
    "        document_embeddings.append(embeddings)\n",
    "        collection.add(ids=[str(i)], embeddings=embeddings, documents=[doc])\n",
    "    end = time.time()\n",
    "\n",
    "    runtime = end - start\n",
    "    print(f\"Embedding Time: {runtime:.2f}s\")\n",
    "    return document_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Output Methods`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `get_output_main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_main(desired_columns, document_embeddings):\n",
    "    start = time.time()\n",
    "\n",
    "    desired_columns = liste_zu_string(desired_columns)\n",
    "\n",
    "    prompt_embeddings = ollama.embeddings(model=\"mxbai-embed-large:latest\", prompt=desired_columns)\n",
    "\n",
    "    retrieval_results = retrieve_relevant_documents(prompt_embeddings)\n",
    "\n",
    "    similarity = calculate_similarity(document_embeddings, prompt_embeddings, retrieval_results)\n",
    "\n",
    "    generate_output(desired_columns, retrieval_results, similarity)\n",
    "\n",
    "    end = time.time()\n",
    "    runtime = end - start\n",
    "    print(f\"Runtime: {runtime:.2f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `retrieve_relevant_documents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_documents(embedded_prompt):\n",
    "    retrieval_results = collection.query(query_embeddings=embedded_prompt[\"embedding\"], n_results=3)\n",
    "    return retrieval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `calculate_similarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(document_embeddings, embedded_prompt, retrieval_results):\n",
    "    # document_vector = np.array(document_embeddings[0][int(retrieval_results[\"ids\"][0][0])]).reshape(1, -1)\n",
    "    # prompt_vector = np.array(embedded_prompt[\"embedding\"]).reshape(1, -1)\n",
    "    # similarity = cosine_similarity(document_vector, prompt_vector).flatten()[0]\n",
    "\n",
    "    # return similarity\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    prompt_vector = np.array(embedded_prompt[\"embedding\"]).reshape(1, -1)\n",
    "    for i in range(len(retrieval_results[\"ids\"][0])):\n",
    "        document_vector = np.array(document_embeddings[int(retrieval_results[\"ids\"][0][i])][0]).reshape(1, -1)\n",
    "        similarities.append(cosine_similarity(document_vector, prompt_vector).flatten()[0])\n",
    "\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `generate_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(desired_columns, retrieval_results, similarity):\n",
    "\n",
    "    PROMPT = f\"Please check if there is a report containing the columns '{desired_columns}'. If such a report exists, provide the report name.\"\n",
    "\n",
    "    output = ollama.generate(\n",
    "        model=\"gemma2:2b\",\n",
    "        prompt=f\"Using this data: {retrieval_results[\"documents\"][0][0]}. Respond to this prompt: {PROMPT}\",\n",
    "    )\n",
    "\n",
    "    print(output[\"response\"])\n",
    "    print(\"Reports with highest Similarity:\")\n",
    "    for i, doc in enumerate(retrieval_results[\"documents\"][0]):\n",
    "        match = re.search(r\"Report Name '.*?'\", retrieval_results[\"documents\"][0][i])\n",
    "        if match:\n",
    "            print(f\"Similarity for {match.group(0)}: {round(similarity[i] * 100, 2)}%\")\n",
    "        else:\n",
    "            print(f\"Similarity for {retrieval_results[\"documents\"][0][i]}: {round(similarity[i] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
