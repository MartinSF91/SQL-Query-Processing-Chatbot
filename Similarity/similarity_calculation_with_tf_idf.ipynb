{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import glob\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 400)\n",
    "import re\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_query_similarity_with_tf_idf():\n",
    "\n",
    "    # migrated_queries = read_in_excel_files(\"../Query Processing/1_migrated_excel_queries/*.xlsx\")\n",
    "    migrated_queries = read_in_excel_files(\"../Query Processing/2_new_excel_queries/*.xlsx\")\n",
    "    migrated_queries_preprocessed = preprocess_query_df(migrated_queries, \"new\")\n",
    "\n",
    "    new_queries = read_in_excel_files(\"../Query Processing/2_new_excel_queries/*.xlsx\")\n",
    "    new_queries_preprocessed = preprocess_query_df(new_queries, \"new1\")\n",
    "\n",
    "    return calculate_query_similarity(migrated_queries_preprocessed, new_queries_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 14:41:46,829 - INFO - Successfully read 1 excel file(s) from ../Query Processing/2_new_excel_queries/*.xlsx.\n",
      "2025-04-01 14:41:46,830 - INFO - Started preprocess_query_df for new queries.\n",
      "2025-04-01 14:42:40,029 - INFO - Preprocessing of new queries successful.\n",
      "2025-04-01 14:42:40,089 - INFO - Successfully read 1 excel file(s) from ../Query Processing/2_new_excel_queries/*.xlsx.\n",
      "2025-04-01 14:42:40,089 - INFO - Started preprocess_query_df for new queries.\n",
      "2025-04-01 14:43:34,692 - INFO - Preprocessing of new queries successful.\n"
     ]
    }
   ],
   "source": [
    "res = calculate_query_similarity_with_tf_idf()\n",
    "res.to_excel(\"./Results/similarity_report_tf_idf.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `read_in_excel_files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_excel_files(PATH):\n",
    "    try:\n",
    "        excel_data = glob.glob(PATH)\n",
    "\n",
    "        dataframes = [pd.read_excel(data, engine=\"openpyxl\") for data in excel_data]\n",
    "        query_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "        logging.info(f\"Successfully read {len(excel_data)} excel file(s) from {PATH}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in reading excel files: {e}\")\n",
    "\n",
    "    return query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `preprocess_query_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query_df(query_df, QUERY_IDENTIFIER):\n",
    "    logging.info(f\"Started {preprocess_query_df.__name__} for {QUERY_IDENTIFIER} queries.\")\n",
    "\n",
    "    query_df = query_df.dropna(subset=[\"SQL\"]).fillna(\"\")\n",
    "\n",
    "    query_df[\"SQL\"] = (query_df[\"SQL\"]\n",
    "                       .str.replace('ê', 'e').str.replace('é', 'e').str.replace('è', 'e').str.replace('à', 'a').str.replace('ç', 'c')\n",
    "                       .str.replace('ô', 'o').str.replace('û', 'u').str.replace('ù', 'u').str.replace('î', 'i').str.replace('ï', 'i')\n",
    "                       .str.replace('â', 'a').str.replace('ä', 'a').str.replace('ö', 'o').str.replace('ü', 'u').str.replace('ÿ', 'y')\n",
    "                       .str.replace('ñ', 'n').str.replace('É', 'E').str.replace('È', 'E').str.replace('À', 'A').str.replace('Ç', 'C')\n",
    "                       .str.replace('Ô', 'O').str.replace('Û', 'U').str.replace('Ù', 'U').str.replace('Î', 'I').str.replace('Ï', 'I')\n",
    "                       .str.replace('Â', 'A').str.replace('Ä', 'A').str.replace('Ö', 'O').str.replace('Ü', 'U').str.replace('Ÿ', 'Y')\n",
    "                       .str.replace('Ñ', 'N')\n",
    "    )\n",
    "\n",
    "    with_pattern = r'WITH\\s+\"\\w+\"\\s+AS\\s*\\(.*?\\)\\s*SELECT'\n",
    "    pattern_2 = r'\"[^\"]*\"\\.'\n",
    "    pattern_3 = r'\\w+\\.'\n",
    "\n",
    "    for index, query in enumerate(query_df[\"SQL\"]):\n",
    "        formatted_query = query.upper()\n",
    "        formatted_query = sqlparse.format(formatted_query, reindent=True, keyword_case='upper', strip_comments=True).strip()\n",
    "        formatted_query = formatted_query.replace(\"'\", '\"').replace(\"\\n\", \" \")\n",
    "        formatted_query = re.sub(with_pattern, 'SELECT', formatted_query, flags=re.DOTALL)\n",
    "        formatted_query = re.sub(pattern_2, '', formatted_query)\n",
    "        formatted_query = re.sub(pattern_3, '', formatted_query)\n",
    "        formatted_query = \" \".join(formatted_query.split())\n",
    "        formatted_query = re.sub(r'\"(\\w+)\" AS \"\\1\"', r'\"\\1\"', formatted_query)\n",
    "        formatted_query = re.sub(r'(\"\\w+\")\\s+\"\\w+\"', r'\\1', formatted_query)\n",
    "\n",
    "        query_df.at[index, 'SQL'] = formatted_query\n",
    "\n",
    "    logging.info(f\"Preprocessing of {QUERY_IDENTIFIER} queries successful.\")\n",
    "\n",
    "    return query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `calculate_query_similarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_query_similarity(migrated_queries_preprocessed, new_queries_preprocessed):\n",
    "\n",
    "#     vectorizer = TfidfVectorizer()\n",
    "#     tfidf_migrated = vectorizer.fit_transform(migrated_queries_preprocessed['SQL'])\n",
    "#     tfidf_new = vectorizer.transform(new_queries_preprocessed['SQL'])\n",
    "\n",
    "#     similarity_matrix = cosine_similarity(tfidf_new, tfidf_migrated)\n",
    "\n",
    "#     similarity = []\n",
    "\n",
    "#     for i in range(len(new_queries_preprocessed)):\n",
    "#         for j in range(len(migrated_queries_preprocessed)):\n",
    "#             similarity.append({\n",
    "#                 'new_report_name': new_queries_preprocessed['Product Name'][i],\n",
    "#                 'migrated_report_name': migrated_queries_preprocessed['Report Name'][j],\n",
    "#                 'similarity': similarity_matrix[i][j],\n",
    "#                 'new_report_sql': new_queries_preprocessed['SQL'][i],\n",
    "#                 'migrated_report_sql': migrated_queries_preprocessed['SQL'][j],\n",
    "#             })\n",
    "\n",
    "#     similarity_df = pd.DataFrame(similarity).drop_duplicates(subset=[\"new_report_name\", \"migrated_report_name\"]).sort_values(by=['new_report_name', 'similarity'], ascending=[True, False])\n",
    "#     similarity_df[\"row_number\"] = similarity_df.groupby(\"new_report_name\").cumcount() + 1\n",
    "\n",
    "#     return similarity_df[similarity_df[\"row_number\"] < 4]\n",
    "def calculate_query_similarity(migrated_queries_preprocessed, new_queries_preprocessed):\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_migrated = vectorizer.fit_transform(migrated_queries_preprocessed['SQL'])\n",
    "    tfidf_new = vectorizer.transform(new_queries_preprocessed['SQL'])\n",
    "\n",
    "    similarity_matrix = cosine_similarity(tfidf_new, tfidf_migrated)\n",
    "\n",
    "    similarity = []\n",
    "\n",
    "    for i in range(len(new_queries_preprocessed)):\n",
    "        for j in range(len(migrated_queries_preprocessed)):\n",
    "            similarity.append({\n",
    "                'new_report_name': str(new_queries_preprocessed['Product Name'][i]).strip(),\n",
    "                'new_report_name_1': str(migrated_queries_preprocessed['Product Name'][j]).strip(),\n",
    "                'similarity': similarity_matrix[i][j],\n",
    "                'new_report_sql': str(new_queries_preprocessed['SQL'][i]).strip(),\n",
    "                'new_report_sql_1': str(migrated_queries_preprocessed['SQL'][j]).strip(),\n",
    "            })\n",
    "\n",
    "    similarity = [entry for entry in similarity if entry['new_report_name'] != entry['new_report_name_1']]\n",
    "\n",
    "    similarity_df = pd.DataFrame(similarity).drop_duplicates(subset=[\"new_report_name\", \"new_report_name_1\"]).sort_values(by=['new_report_name', 'similarity'], ascending=[True, False])\n",
    "    similarity_df[\"row_number\"] = similarity_df.groupby(\"new_report_name\").cumcount() + 1\n",
    "\n",
    "    return similarity_df[similarity_df[\"row_number\"] < 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
